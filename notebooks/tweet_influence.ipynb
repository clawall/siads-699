{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "afe7dacd-c918-4617-9bd8-e5673cbbee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from __future__ import annotations\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from arch.univariate.base import DataScaleWarning\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DataScaleWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a7ab7659-cf60-4f3f-a35e-d0fd2891fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zoneinfo import ZoneInfo\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "###############################################################################\n",
    "# -----------------------------  CONFIG  --------------------------------------\n",
    "###############################################################################\n",
    "MARKET_TZ       = ZoneInfo('US/Eastern')\n",
    "TRADING_START   = '09:30'\n",
    "TRADING_END     = '16:00'\n",
    "TOPIC_THRESH    = 0.80\n",
    "ARIMA_ORDER     = (1, 0, 0)        # AR(1)\n",
    "KERNEL          = np.array([1.0])  # single‑minute impulse\n",
    "RET_SCALE = 1000        # 1 ≤ RET_SCALE ≤ 1000 recommended by arch\n",
    "###############################################################################\n",
    "\n",
    "# ────────────────────────  helpers  ───────────────────────────────────────────\n",
    "def to_market_time(utc_ts: pd.Timestamp) -> pd.Timestamp:\n",
    "    \"\"\"UTC → naive NY   (tz info stripped for speed).\"\"\"\n",
    "    return utc_ts.tz_convert(MARKET_TZ).tz_localize(None)\n",
    "\n",
    "def first_session_minute(ts_naive: pd.Timestamp,\n",
    "                         price_index: pd.DatetimeIndex) -> Optional[pd.Timestamp]:\n",
    "    \"\"\"Map a timestamp to first trading minute at/after ts in price_index.\"\"\"\n",
    "    if ts_naive > price_index[-1]:\n",
    "        return None\n",
    "    if ts_naive in price_index:\n",
    "        return ts_naive\n",
    "    pos = price_index.get_indexer([ts_naive], method='bfill')[0]\n",
    "    return price_index[pos] if pos != -1 else None\n",
    "\n",
    "def prepare_price_df(raw: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Return minutely log‑returns on a *regular* grid (NaNs for gaps).\"\"\"\n",
    "    ts = (pd.to_datetime(raw['timestamp'])\n",
    "            .dt.tz_localize(MARKET_TZ, nonexistent='shift_forward',\n",
    "                            ambiguous='NaT')\n",
    "            .dt.tz_localize(None))\n",
    "\n",
    "    px = (raw.assign(timestamp=ts)\n",
    "              .set_index('timestamp')\n",
    "              .between_time(TRADING_START, TRADING_END)\n",
    "              ['avg_price']\n",
    "              .resample('1min')          # regular grid\n",
    "              .last()\n",
    "              .asfreq('1min')            # keep NaNs instead of dropping minutes\n",
    "           )\n",
    "\n",
    "    # convert to returns, drop NaNs from both resample and diff\n",
    "    returns = np.log(px).diff().dropna()\n",
    "\n",
    "    return returns\n",
    "\n",
    "def fit_baseline_garch(returns: pd.Series) -> pd.Series:\n",
    "    \"\"\"ARIMA(1) + GARCH(1,1) → squared standardised residuals.\"\"\"\n",
    "    ar_res   = ARIMA(returns, order=ARIMA_ORDER, trend='n').fit()\n",
    "    resid    = ar_res.resid\n",
    "    garch    = arch_model(resid, mean='Zero', vol='Garch', p=1, q=1).fit(disp='off')\n",
    "    return garch.std_resid ** 2\n",
    "\n",
    "def impulse_series(event_ts: pd.Timestamp,\n",
    "                   base_index: pd.DatetimeIndex,\n",
    "                   kernel: np.ndarray = KERNEL) -> pd.Series:\n",
    "    \"\"\"Series aligned to base_index, populated with kernel starting at event_ts.\"\"\"\n",
    "    s = pd.Series(0.0, index=base_index, name='impulse')\n",
    "    if event_ts in s.index:\n",
    "        start = s.index.get_loc(event_ts)\n",
    "        end   = min(start + len(kernel), len(s))\n",
    "        s.iloc[start:end] = kernel[:end - start]\n",
    "    return s\n",
    "\n",
    "# ──────────────────────  MAIN FUNCTION  ──────────────────────────────────────\n",
    "def run_event_study(tweets_df: pd.DataFrame,\n",
    "                    prices_df: pd.DataFrame,\n",
    "                    tickers_topics_df: pd.DataFrame,\n",
    "                    ticker_col_guess: list[str] = ('ticker', 'sym_root', 'symbol')\n",
    "                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tweets_df            : tweets + topic columns (FinBERT, zero‑shot, etc.)\n",
    "    prices_df            : *single big* TAQ‑style table with at least\n",
    "                           ['timestamp', 'avg_price', <ticker column>]\n",
    "    tickers_topics_df    : mapping table with columns ['ticker', 'topic']\n",
    "    \"\"\"\n",
    "    # 1) detect which column holds the ticker symbol\n",
    "    ticker_col = next((c for c in ticker_col_guess if c in prices_df.columns), None)\n",
    "    if ticker_col is None:\n",
    "        raise ValueError('Could not find a ticker column in prices_df.')\n",
    "\n",
    "    # 2) build dict {topic: [tickers]} once\n",
    "    topic_to_tickers = (tickers_topics_df.groupby('topic')['ticker']\n",
    "                                        .apply(list)\n",
    "                                        .to_dict())\n",
    "    topic_cols = [c for c in tweets_df.columns if c in topic_to_tickers]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 3) iterate over *each ticker* present in prices_df\n",
    "    for ticker, raw_px in prices_df.groupby(ticker_col, sort=False):\n",
    "        returns = prepare_price_df(raw_px)\n",
    "        if returns.empty:\n",
    "            continue\n",
    "        returns_scaled = returns * RET_SCALE\n",
    "        price_idx   = returns.index\n",
    "        std_resid2  = fit_baseline_garch(returns)\n",
    "\n",
    "        # select tweets whose high‑score topics map to THIS ticker\n",
    "        def tweet_relevant(row) -> bool:\n",
    "            high_topics = [t for t in topic_cols if row[t] >= TOPIC_THRESH]\n",
    "            return any(ticker in topic_to_tickers.get(t, []) for t in high_topics)\n",
    "\n",
    "        for _, tw in tweets_df.loc[tweets_df.apply(tweet_relevant, axis=1)].iterrows():\n",
    "            evt_ts = first_session_minute(\n",
    "                to_market_time(pd.to_datetime(tw['timestamp'])),\n",
    "                price_idx\n",
    "            )\n",
    "            if evt_ts is None:\n",
    "                continue\n",
    "\n",
    "            imp = impulse_series(evt_ts, std_resid2.index)\n",
    "            df_reg = pd.concat({'y': std_resid2, 'impulse': imp}, axis=1).dropna()\n",
    "\n",
    "            X   = sm.add_constant(df_reg['impulse'])\n",
    "            ols = sm.OLS(df_reg['y'], X).fit()\n",
    "\n",
    "            results.append({\n",
    "                'handle'  : tw['handle'],\n",
    "                'tweet_id': tw['id'],\n",
    "                'ticker'  : ticker,\n",
    "                'gamma'   : ols.params['impulse'],\n",
    "                'pvalue'  : ols.pvalues['impulse']\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "548cbebd-7454-4d6b-a0b0-1a6546d88619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clawall/estudo/siads-699/.env/lib/python3.9/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 4. The message is:\n",
      "Inequality constraints incompatible\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      handle             tweet_id ticker       gamma        pvalue\n",
      "9   elonmusk  1146392791062212608   TSLA  150.137362  9.571517e-32\n",
      "14  elonmusk  1130200352576303106   TSLA   51.933704  5.004929e-05\n",
      "10  elonmusk  1140413721631551489   TSLA   38.590675  2.582861e-03\n",
      "18  elonmusk  1113581319890526208   TSLA   32.749283  1.054827e-02\n"
     ]
    }
   ],
   "source": [
    "# --- 1. tweets ---------------------------------------------------------------\n",
    "# tweets_df = pd.read_parquet('tweets.parquet')           # already has topic columns\n",
    "tweets_df = pd.read_csv('../data/tweets_with_sentiment_and_topic.csv')\n",
    "\n",
    "# --- 2. prices ---------------------------------------------------------------\n",
    "prices_df = pd.read_parquet(\n",
    "    '../data/taq/',\n",
    "    engine='pyarrow',\n",
    "    filters=[\n",
    "        ('SYM_ROOT', '==', 'TSLA')\n",
    "        # ('year', '==', 2024)\n",
    "    ]\n",
    ")\n",
    "prices_df.columns = ['timestamp', 'avg_price', 'ticker', 'year']\n",
    "del prices_df['year']\n",
    "\n",
    "# --- 3. ticker‑to‑topic map --------------------------------------------------\n",
    "tickers_topics_df = pd.read_csv('../data/05_people_stock_link_simplified.csv', sep=';')   # columns: ticker,topic\n",
    "tickers_topics_df = tickers_topics_df[['industry', 'ticker']]\n",
    "tickers_topics_df.columns = ['topic', 'ticker']\n",
    "# --- 4. run study ------------------------------------------------------------\n",
    "result_df = run_event_study(tweets_df, prices_df, tickers_topics_df)\n",
    "\n",
    "# e.g. keep only strongly significant results\n",
    "sig = result_df[result_df['pvalue'] < 0.05]\n",
    "print(sig.sort_values('pvalue').head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
